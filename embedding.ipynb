{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnxruntime in /home/himanshi/.local/lib/python3.10/site-packages (1.17.1)\n",
      "Requirement already satisfied: coloredlogs in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (23.1)\n",
      "Requirement already satisfied: protobuf in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (4.24.4)\n",
      "Requirement already satisfied: sympy in /home/himanshi/.local/lib/python3.10/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/himanshi/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/himanshi/.local/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: insightface in /home/himanshi/.local/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.26.4)\n",
      "Requirement already satisfied: onnx in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (3.8.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from insightface) (9.0.1)\n",
      "Requirement already satisfied: scipy in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.4.1.post1)\n",
      "Requirement already satisfied: scikit-image in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (0.22.0)\n",
      "Requirement already satisfied: easydict in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.13)\n",
      "Requirement already satisfied: cython in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (3.0.9)\n",
      "Requirement already satisfied: albumentations in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (1.4.2)\n",
      "Requirement already satisfied: prettytable in /home/himanshi/.local/lib/python3.10/site-packages (from insightface) (3.9.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations->insightface) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/himanshi/.local/lib/python3.10/site-packages (from albumentations->insightface) (4.9.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in /home/himanshi/.local/lib/python3.10/site-packages (from albumentations->insightface) (4.9.0.80)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-image->insightface) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-image->insightface) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-image->insightface) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-image->insightface) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-image->insightface) (0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-learn->insightface) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/himanshi/.local/lib/python3.10/site-packages (from scikit-learn->insightface) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/himanshi/.local/lib/python3.10/site-packages (from matplotlib->insightface) (2.8.2)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/himanshi/.local/lib/python3.10/site-packages (from onnx->insightface) (4.24.4)\n",
      "Requirement already satisfied: wcwidth in /home/himanshi/.local/lib/python3.10/site-packages (from prettytable->insightface) (0.2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/himanshi/.local/lib/python3.10/site-packages (from requests->insightface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->insightface) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->insightface) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/himanshi/.local/lib/python3.10/site-packages (from requests->insightface) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime\n",
    "!pip install insightface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/himanshi/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/himanshi/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/himanshi/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/himanshi/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/himanshi/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "from insightface.utils import face_align\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshi/.local/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  0  images\n",
      "No face detected in image:  00001.png\n",
      "No face detected in image:  00006.png\n",
      "No face detected in image:  00007.png\n",
      "No face detected in image:  00009.png\n",
      "No face detected in image:  00011.png\n",
      "No face detected in image:  00015.png\n",
      "No face detected in image:  00016.png\n",
      "No face detected in image:  00017.png\n",
      "No face detected in image:  00018.png\n",
      "No face detected in image:  00019.png\n",
      "No face detected in image:  00021.png\n",
      "No face detected in image:  00022.png\n",
      "No face detected in image:  00024.png\n",
      "No face detected in image:  00025.png\n",
      "No face detected in image:  00028.png\n",
      "No face detected in image:  00029.png\n",
      "No face detected in image:  00030.png\n",
      "No face detected in image:  00032.png\n",
      "No face detected in image:  00033.png\n",
      "No face detected in image:  00034.png\n",
      "No face detected in image:  00035.png\n",
      "No face detected in image:  00036.png\n",
      "No face detected in image:  00037.png\n",
      "No face detected in image:  00038.png\n",
      "No face detected in image:  00039.png\n",
      "No face detected in image:  00040.png\n",
      "No face detected in image:  00042.png\n",
      "No face detected in image:  00043.png\n",
      "No face detected in image:  00045.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m img_path \u001b[38;5;241m=\u001b[39m dataset_path \u001b[38;5;241m+\u001b[39m img_files[i]\n\u001b[1;32m     13\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m---> 14\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo face detected in image: \u001b[39m\u001b[38;5;124m'\u001b[39m, img_files[i])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/insightface/app/face_analysis.py:75\u001b[0m, in \u001b[0;36mFaceAnalysis.get\u001b[0;34m(self, img, max_num)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m taskname\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetection\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(face)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/insightface/model_zoo/landmark.py:91\u001b[0m, in \u001b[0;36mLandmark.get\u001b[0;34m(self, img, face)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#assert input_size==self.input_size\u001b[39;00m\n\u001b[1;32m     90\u001b[0m blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(aimg, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_std, input_size, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_mean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_mean), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 91\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m:\n\u001b[1;32m     93\u001b[0m     pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## generate and save embeddings for all images in the dataset\n",
    "# dataset_path = 'datasets/ffhq256/'\n",
    "\n",
    "# import os\n",
    "# img_files = os.listdir(dataset_path)\n",
    "# img_files.sort()\n",
    "\n",
    "# start_index = 0\n",
    "# end_index = len(img_files)\n",
    "\n",
    "# for i in range(start_index, end_index):\n",
    "#     img_path = dataset_path + img_files[i]\n",
    "#     img = cv2.imread(img_path)\n",
    "#     faces = app.get(img)    \n",
    "#     if len(faces) == 0:\n",
    "#         print('No face detected in image: ', img_files[i])\n",
    "#         continue\n",
    "#     face = faces[0]\n",
    "#     embedding = face.embedding\n",
    "#     file_name = dataset_path + 'embeddings/' + img_files[i].split('.')[0] + '.npy'\n",
    "#     np.save(file_name, embedding)\n",
    "    \n",
    "#     # copy the image to another folder\n",
    "#     img_copy_path = dataset_path + 'images/' + img_files[i]\n",
    "#     cv2.imwrite(img_copy_path, img)\n",
    "\n",
    "#     if i % 1000 == 0:\n",
    "#         print('Processed ', i, ' images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: facenet-pytorch in /home/himanshi/.local/lib/python3.10/site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy in /home/himanshi/.local/lib/python3.10/site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/himanshi/.local/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: torchvision in /home/himanshi/.local/lib/python3.10/site-packages (from facenet-pytorch) (0.17.1)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from facenet-pytorch) (9.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/himanshi/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->facenet-pytorch) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->facenet-pytorch) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/himanshi/.local/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.7.22)\n",
      "Requirement already satisfied: torch==2.2.1 in /home/himanshi/.local/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.2.1)\n",
      "Requirement already satisfied: filelock in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/himanshi/.local/lib/python3.10/site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/himanshi/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision->facenet-pytorch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/himanshi/.local/lib/python3.10/site-packages (from jinja2->torch==2.2.1->torchvision->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/himanshi/.local/lib/python3.10/site-packages (from sympy->torch==2.2.1->torchvision->facenet-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# load resnet from pretrained model 20180402-114759-vggface2.pt\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 3)\n",
      "torch.Size([1, 3, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# img = cv2.imread('datasets/ffhq256/00049.png')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "\n",
    "# # Get cropped and prewhitened image tensor\n",
    "# img_cropped = mtcnn(img, save_path='datasets/00049_cropped.png')\n",
    "# img_cropped.shape\n",
    "\n",
    "img_to_show = cv2.imread('datasets/ffhq256_pp/train/images/00000.png')\n",
    "img_to_show = cv2.cvtColor(img_to_show, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img_to_show)\n",
    "print(img_to_show.shape)\n",
    "\n",
    "img_to_show = img_to_show.transpose(2, 0, 1)\n",
    "img_to_show = torch.tensor(img_to_show.reshape(1, img_to_show.shape[0], img_to_show.shape[1], img_to_show.shape[2]))\n",
    "print(img_to_show.shape)\n",
    "\n",
    "# img_embedding = resnet(img_to_show)\n",
    "# print(img_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  50000  images\n",
      "No face detected in image:  50521.png\n",
      "Processed  51000  images\n",
      "Processed  52000  images\n",
      "No face detected in image:  52116.png\n",
      "No face detected in image:  52294.png\n",
      "Processed  53000  images\n",
      "Processed  54000  images\n",
      "No face detected in image:  54217.png\n",
      "Processed  55000  images\n",
      "Processed  56000  images\n",
      "Processed  57000  images\n",
      "Processed  58000  images\n",
      "Processed  59000  images\n",
      "Processed  60000  images\n",
      "Processed  61000  images\n",
      "Processed  62000  images\n",
      "Processed  63000  images\n",
      "Processed  64000  images\n",
      "Processed  65000  images\n",
      "Processed  66000  images\n",
      "Processed  67000  images\n",
      "Processed  68000  images\n",
      "Processed  69000  images\n",
      "No face detected in image:  69090.png\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m img_copy_path \u001b[38;5;241m=\u001b[39m dataset_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m img_files[i]\n\u001b[1;32m     16\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m img_cropped \u001b[38;5;241m=\u001b[39m mtcnn(img, save_path\u001b[38;5;241m=\u001b[39mimg_copy_path)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_cropped \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "## generate and save embeddings for all images in the dataset\n",
    "import numpy as np\n",
    "dataset_path = 'datasets/ffhq256/'\n",
    "\n",
    "import os\n",
    "img_files = os.listdir(dataset_path)\n",
    "img_files.sort()\n",
    "\n",
    "start_index = 49053\n",
    "end_index = len(img_files)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "    img_path = dataset_path + img_files[i]\n",
    "    img_copy_path = dataset_path + 'images/' + img_files[i]\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_cropped = mtcnn(img, save_path=img_copy_path)\n",
    "    if img_cropped is None:\n",
    "        print('No face detected in image: ', img_files[i])\n",
    "        continue\n",
    "\n",
    "    if img_cropped.shape[0] > 1:\n",
    "        # remove the other faces\n",
    "        for j in range(1, img_cropped.shape[0]):\n",
    "            os.remove(img_copy_path.split('.')[0] + '_' + str(j+1) + '.png')\n",
    "        \n",
    "        img_cropped = img_cropped[0].reshape(1, 3, 160, 160)\n",
    "\n",
    "\n",
    "    try:\n",
    "        img_embedding = resnet(img_cropped)\n",
    "    except:\n",
    "        print('Error in processing image: ', img_files[i])\n",
    "        # remove the image copy\n",
    "        os.remove(img_copy_path)\n",
    "        continue\n",
    "    \n",
    "    embedding = img_embedding.detach().numpy()\n",
    "\n",
    "    file_name = dataset_path + 'embeddings/' + img_files[i].split('.')[0] + '.npy'\n",
    "    np.save(file_name, embedding)\n",
    "\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print('Processed ', i, ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv datasets/ffhq256_new/embeddings datasets/ffhq256_new/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split intro train test\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "dataset_path = 'datasets/ffhq256/'\n",
    "img_files = os.listdir(dataset_path + 'images/')\n",
    "emb_files = os.listdir(dataset_path + 'embeddings/')\n",
    "img_files.sort()\n",
    "emb_files.sort()\n",
    "\n",
    "train_path = dataset_path + 'train/'\n",
    "test_path = dataset_path + 'test/'\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    os.makedirs(test_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets/ffhq256_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/datasets/ffhq256/train': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv /datasets/ffhq256/train /datasets/ffhq256_new/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
