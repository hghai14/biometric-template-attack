{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pip install facenet_pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T06:27:00.041073Z","iopub.status.busy":"2024-04-08T06:27:00.040696Z","iopub.status.idle":"2024-04-08T06:27:00.068743Z","shell.execute_reply":"2024-04-08T06:27:00.067323Z","shell.execute_reply.started":"2024-04-08T06:27:00.041044Z"},"id":"m2_4Z70-16V0","metadata":{},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import cv2\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T06:27:04.010050Z","iopub.status.busy":"2024-04-08T06:27:04.009563Z","iopub.status.idle":"2024-04-08T06:27:04.016685Z","shell.execute_reply":"2024-04-08T06:27:04.015324Z","shell.execute_reply.started":"2024-04-08T06:27:04.010006Z"},"metadata":{},"trusted":true},"outputs":[],"source":["import os\n","import random\n","def get_random_index(start, end, n, seed = -1):\n","    if seed == -1:\n","        random.seed()\n","    else:\n","        random.seed(seed)\n","    return sorted(random.sample(range(start, end), n))\n","    "]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"metadata":{}},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/himanshi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# generate embeddings\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","\n","mtcnn = MTCNN(keep_all=True)\n","\n","# load resnet from pretrained model 20180402-114759-vggface2.pt\n","resnet = InceptionResnetV1(pretrained='vggface2').eval()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"izitO0OzjwpM","metadata":{}},"outputs":[],"source":["def block_based_warping(image, block_size, key, maximum_pixel_offset, k_size = 15):\n","    # Create regular grid of blocks\n","    if block_size == 0:\n","        warped_image = image.copy()\n","    else:\n","        rows, cols = image.shape[:2]\n","        block_rows, block_cols = rows // block_size, cols // block_size\n","\n","        # Initialize the warped output image\n","        warped_image = np.zeros_like(image)\n","\n","        # Set random seed based on the key\n","        np.random.seed(key)\n","\n","        for block_row in range(block_rows):\n","            for block_col in range(block_cols):\n","                # Get block indices\n","                start_row = block_row * block_size\n","                end_row = start_row + block_size\n","                start_col = block_col * block_size\n","                end_col = start_col + block_size\n","\n","                # Calculate random pixel offsets\n","                row_offset = np.random.randint(-maximum_pixel_offset, maximum_pixel_offset)\n","                col_offset = np.random.randint(-maximum_pixel_offset, maximum_pixel_offset)\n","\n","                # Calculate the warped grid for the block\n","                warped_start_row = max(0, start_row + row_offset)\n","                warped_end_row = min(rows, end_row + row_offset)\n","                warped_start_col = max(0, start_col + col_offset)\n","                warped_end_col = min(cols, end_col + col_offset)\n","\n","                # Perform spline interpolation to warp the block\n","                warped_block = cv2.resize(image[warped_start_row:warped_end_row, warped_start_col:warped_end_col],\n","                                        (block_size, block_size))\n","\n","                # Assign the warped block to the corresponding region in the output image\n","                warped_image[start_row:end_row, start_col:end_col] = warped_block\n","                \n","    # Apply Gaussian blur to smoothen the output image\n","    if k_size != 0:\n","        kernel_size = (k_size, k_size)  # Increase the kernel size for more smoothing\n","        smoothed_image = cv2.GaussianBlur(warped_image, kernel_size, 0)\n","    else:\n","        smoothed_image = warped_image\n","    return smoothed_image"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"lQ_E4sqdj0fe","outputId":"6207bfd5-ae5a-4e65-d33f-f57af63b7614"},"outputs":[],"source":["# # Setting the input parameters\n","# image = cv2.imread('ffhq256_pp/test/images/69001.png', cv2.IMREAD_COLOR)\n","# block_size = 20\n","# key = 1234\n","# maximum_pixel_offset = 3\n","\n","# # Calling the warping function\n","# warped_image = block_based_warping(image, block_size, key, maximum_pixel_offset)\n","\n","# # Displaying the original and warped images\n","# plt.imshow(image)\n","# plt.show()\n","# plt.imshow(warped_image)\n","# plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T06:27:34.104710Z","iopub.status.busy":"2024-04-08T06:27:34.104140Z","iopub.status.idle":"2024-04-08T06:27:34.110434Z","shell.execute_reply":"2024-04-08T06:27:34.109223Z","shell.execute_reply.started":"2024-04-08T06:27:34.104673Z"},"trusted":true},"outputs":[],"source":["# random.seed(0)\n","# print(get_random_index(0, 100, 5, 0))"]},{"cell_type":"code","execution_count":10,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating folder:  warped_dataset/8_4_15\n","No face detected in image:  69081\n","No face detected in image:  69090\n"]}],"source":["# function for above code\n","def generate_warped_dataset(image_data_path, samples_index, target_folder, block_size, maximum_pixel_offset, k_size, key):\n","    for i in samples_index:\n","        img = cv2.imread(image_data_path + \"/{:05d}.png\".format(i))\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        # warp image using block based warping\n","        warped_image = block_based_warping(img, block_size, key, maximum_pixel_offset, k_size)\n","\n","        # detect face in the unwarped image and save it\n","        mtcnn(img, save_path = target_folder + \"/original_images/{:05d}.png\".format(i))\n","\n","        # detect face in the warped image and save it\n","        img_cropped = mtcnn(warped_image, save_path = target_folder + \"/images/{:05d}.png\".format(i))\n","\n","        # if no face detected, remove the image OR if multiple faces detected, remove the extra faces\n","        if img_cropped is None:\n","            print(\"No face detected in image: \", i)\n","            continue\n","        if img_cropped.shape[0] > 1:\n","            for j in range(1, img_cropped.shape[0]):\n","                os.remove(target_folder + \"/images/{:05d}_{}.png\".format(i,j+1))\n","\n","            img_cropped = img_cropped[0]\n","\n","        # generate embedding\n","        img_cropped = img_cropped.reshape(1,3, 160, 160)\n","        try:\n","            img_embedding = resnet(img_cropped)\n","        except:\n","            print('Error in processing image:',i)\n","            # remove the image copy\n","            os.remove(target_folder + \"/images/{:05d}.png\".format(i))\n","            continue\n","\n","        embedding = img_embedding.detach().numpy()\n","        file_name = target_folder + \"/embeddings/{:05d}.npy\".format(i)\n","        np.save(file_name, embedding)\n","    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# params\n","read_folder = \"datasets/ffhq256\"\n","block_size = 8\n","maximum_pixel_offset = 4\n","k_size = 15\n","key = 1234\n","seed = 0\n","\n","# create save folder\n","save_folder = \"warped_dataset/{}_{}_{}\".format(block_size, maximum_pixel_offset, k_size)\n","\n","if not os.path.exists(save_folder):\n","    print(\"Creating folder: \", save_folder)\n","    os.makedirs(save_folder)\n","\n","# create sub folder for train and test\n","if not os.path.exists(save_folder + \"/train/images\"):\n","    os.makedirs(save_folder + \"/train/images\")\n","    os.makedirs(save_folder + \"/train/embeddings\")\n","    os.makedirs(save_folder + \"/train/original_images\")\n","if not os.path.exists(save_folder + \"/test/images\"):\n","    os.makedirs(save_folder + \"/test/images\")\n","    os.makedirs(save_folder + \"/test/embeddings\")\n","    os.makedirs(save_folder + \"/test/original_images\")\n","\n","# sample 1000 images for train and test\n","train_samples = get_random_index(0,68999,1000,seed)\n","test_samples = range(69000, 70000)\n","\n","# generate warped dataset\n","generate_warped_dataset(read_folder, train_samples, save_folder + \"/train\", block_size, maximum_pixel_offset, k_size, key)\n","generate_warped_dataset(read_folder, test_samples, save_folder + \"/test\", block_size, maximum_pixel_offset, k_size, key)"]},{"cell_type":"code","execution_count":18,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6384911\n"]}],"source":["# compare the embeddings\n","\n","# load any warped image embedding\n","emb = np.load(\"warped_dataset/20_3_9/train/embeddings/00009.npy\")\n","\n","# load the original image embedding\n","emb2 = np.load(\"datasets/ffhq256_pp/train/embeddings/00009.npy\")\n","\n","norm = np.linalg.norm(emb - emb2)\n","print(norm)"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
